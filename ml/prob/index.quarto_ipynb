{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Probability\n",
        "draft: true\n",
        "author:\n",
        "  - name: Martin Laptev\n",
        "    url: https://maptv.github.io\n",
        "date: last-modified\n",
        "image: horst_hist-samples.png\n",
        "categories:\n",
        "  - ml\n",
        "date-format: x\n",
        "format:\n",
        "  html:\n",
        "    include-after-body:\n",
        "      - ../../asset/stamp.html\n",
        "      - ../../asset/style.html\n",
        "      - ../../asset/tooltip.html\n",
        "filters:\n",
        "  - ../../asset/date.lua\n",
        "  - include-code-files\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In this blog post I will discuss a few examples of [probability](https://en.wikipedia.org/wiki/Probability#:~:text=Probability%20is%20the%20branch%20of,event%20and%201%20indicates%20certainty.) in [machine learning](https://en.wikipedia.org/wiki/Machine_learning#:~:text=Machine%20learning%20(ML)%20is%20a%20field%20of%20study%20in%20artificial%20intelligence%20concerned%20with%20the%20development%20and%20study%20of%20statistical%20algorithms%20that%20can%20effectively%20generalize%20and%20thus%20perform%20tasks%20without%20explicit%20instructions.). If you are new to probability, I recommend one of great textbooks that cover the topic and are available for free online, such as [Think Bayes](https://allendowney.github.io/ThinkBayes2) by [Allen Downey](https://www.allendowney.com) and [Bayes Rules!](https://www.bayesrulesbook.com) by [Alicia A. Johnson](https://ajohns24.github.io), Miles Q. Ott, and [Mine Dogucu](https://www.minedogucu.com).\n",
        "\n",
        "[Classification](https://en.wikipedia.org/wiki/Statistical_classification) [algorithms](https://en.wikipedia.org/wiki/Algorithm) algorithms can estimate $n \\times k$ class membership probabilities for each dataset, where n is the number of data points in the dataset and k is the number of classes in the [training dataset](https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets#:~:text=training%20data%20set%2C%5B3%5D%20which%20is%20a%20set%20of%20examples%20used%20to%20fit%20the%20parameters%20(e.g.%20weights%20of%20connections%20between%20neurons%20in%20artificial%20neural%20networks)%20of%20the%20model.). Similarly, the [Gaussian Mixtures](https://scikit-learn.org/stable/modules/mixture.html) [clustering](https://scikit-learn.org/stable/modules/clustering.html) algorithm can generate $n \\times k$ cluster label probabilities.\n",
        "\n",
        "Besides  a data point and the Gaussian Mixtures models can estimate cluster membership probability. point , especially [Logistic Regression](https://en.wikipedia.org/wiki/Logistic_regression) and [Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier). Every classification algorithm can estimate probabilities of belonging to each class.\n",
        "\n",
        "$\\Huge P(A\\vert B)={\\frac {P(B\\vert A)P(A)}{P(B)}}$\n"
      ],
      "id": "db83a1c0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "d151ca0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = sns.load_dataset(\"penguins\")\n",
        "df.head()"
      ],
      "id": "92b6ad08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y = df[\"species\"]\n",
        "X = df.drop(\"species\", axis=1)\n",
        "X = pd.get_dummies(X, columns=[\"island\", \"sex\"])"
      ],
      "id": "7877b681",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "knni = KNNImputer()\n",
        "colnames = X.columns\n",
        "X = knni.fit_transform(X)\n",
        "X = pd.DataFrame(X, columns=colnames)"
      ],
      "id": "908ffb14",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# https://blog.4dcu.be/programming/2021/03/19/Code-Nugget-PCA-with-loadings.html\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA(n_components=2)),\n",
        "])\n",
        "\n",
        "pca_data = pd.DataFrame(\n",
        "    pipeline.fit_transform(X),\n",
        "    columns=[\"PC1\", \"PC2\"],\n",
        "    index=df.index,\n",
        ")\n",
        "pca_data[\"species\"] = df[\"species\"]\n",
        "\n",
        "pca_step = pipeline.steps[1][1]\n",
        "loadings = pd.DataFrame(\n",
        "    pca_step.components_.T,\n",
        "    columns=[\"PC1\", \"PC2\"],\n",
        "    index=X.columns,\n",
        ")\n",
        "\n",
        "def loading_plot(\n",
        "    coeff, labels, scale=1, text_x=None, text_y=None, colors=None, visible=None, ax=plt, arrow_size=0.5\n",
        "):\n",
        "    for i, label in enumerate(labels):\n",
        "        if visible is None or visible[i]:\n",
        "            ax.arrow(\n",
        "                0,\n",
        "                0,\n",
        "                coeff[i, 0] * scale,\n",
        "                coeff[i, 1] * scale,\n",
        "                head_width=arrow_size * scale,\n",
        "                head_length=arrow_size * scale,\n",
        "                color=\"#000\" if colors is None else colors[i],\n",
        "            )\n",
        "            ax.text(\n",
        "                text_x[i] if text_x.all() else coeff[i, 0] * 1.2 * scale,\n",
        "                text_y[i] if text_y.all() else coeff[i, 1] * 1.2 * scale,\n",
        "                label,\n",
        "                color=\"#000\" if colors is None else colors[i],\n",
        "                ha=\"center\",\n",
        "                va=\"center\",\n",
        "            )\n",
        "\n",
        "loadings = loadings * 3.2\n",
        "\n",
        "text_x = loadings[\"PC1\"] * 2.4\n",
        "text_y = loadings[\"PC2\"] * 2.4\n",
        "\n",
        "text_y[\"sex_Male\"] -= .5\n",
        "text_y[\"bill_depth_mm\"] -= .4\n",
        "text_x[\"bill_depth_mm\"] -= .4\n",
        "text_y[\"sex_Female\"] += .5\n",
        "text_y[\"island_Torgersen\"] += .1\n",
        "text_x[\"island_Dream\"] -= .5\n",
        "text_y[\"island_Dream\"] -= .3\n",
        "text_y[\"island_Biscoe\"] += .3\n",
        "text_x[\"island_Biscoe\"] += .3\n",
        "text_x[\"flipper_length_mm\"] += .55\n",
        "text_x[\"body_mass_g\"] += .95\n",
        "text_y[\"body_mass_g\"] -= .05\n",
        "\n",
        "# https://seaborn.pydata.org/generated/seaborn.jointplot.html\n",
        "g = sns.jointplot(data=pca_data, x=\"PC1\", y=\"PC2\", hue=\"species\", ratio=4, marginal_ticks=True, height=8)\n",
        "g.plot_joint(sns.kdeplot, zorder=0, levels=6)\n",
        "g.plot_marginals(sns.rugplot, height=-.025, clip_on=False)\n",
        "# Add loadings\n",
        "loading_plot(loadings[[\"PC1\", \"PC2\"]].values, loadings.index, text_x=text_x, text_y=text_y, scale=2, arrow_size=0.02)\n",
        "\n",
        "# Add variance explained by the\n",
        "plt.xlabel(f\"PC1 ({pca_step.explained_variance_ratio_[0]*100:.2f} %)\")\n",
        "plt.ylabel(f\"PC2 ({pca_step.explained_variance_ratio_[1]*100:.2f} %)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"PCA_with_loadings.png\", dpi=300)\n",
        "plt.show()"
      ],
      "id": "b6371b37",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "sns.displot(df, x=\"bill_length_mm\", kde=True, hue=\"species\", stat=\"count\");"
      ],
      "id": "ab5691b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "sns.displot(df, x=\"bill_length_mm\", kde=True, hue=\"species\", stat=\"density\");\n",
        "plt.show()"
      ],
      "id": "8ae29442",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "sns.displot(df, x=\"bill_length_mm\", kde=True, rug=True, hue=\"species\", stat=\"proportion\");\n",
        "plt.show()"
      ],
      "id": "8a5c65a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, sharey=True)\n",
        "fig.suptitle('PDF and CDF comparision')\n",
        "sns.histplot(df[[\"bill_length_mm\", \"flipper_length_mm\"]], kde=True, ax=axes[0]);\n",
        "sns.ecdfplot(df[[\"bill_length_mm\", \"flipper_length_mm\"]], stat=\"count\", ax=axes[1], legend=False)\n",
        "plt.ylim((0, 375));\n",
        "plt.show()"
      ],
      "id": "a2d243c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "import pathlib"
      ],
      "id": "4d16dc8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "lr = LogisticRegression(max_iter=10000)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "cmd = ConfusionMatrixDisplay.from_estimator(lr, X_test, y_test)\n",
        "plt.show()"
      ],
      "id": "6dc5ee11",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logistic function visualization\n"
      ],
      "id": "5854db29"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "# https://github.com/ageron/handson-ml3/blob/main/04_training_linear_models.ipynb\n",
        "lim = 6\n",
        "t = np.linspace(-lim, lim, 100)\n",
        "sig = 1 / (1 + np.exp(-t))\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot([-lim, lim], [0, 0], \"k-\")\n",
        "plt.plot([-lim, lim], [0.5, 0.5], \"k:\")\n",
        "plt.plot([-lim, lim], [1, 1], \"k:\")\n",
        "plt.plot([0, 0], [-1.1, 1.1], \"k-\")\n",
        "plt.plot(t, sig, \"b-\", linewidth=2, label=r\"$\\sigma(t) = \\dfrac{1}{1 + e^{-t}}$\")\n",
        "plt.xlabel(\"t\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.axis([-lim, lim, -0.1, 1.1])\n",
        "plt.gca().set_yticks([0, 0.25, 0.5, 0.75, 1])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "e63ecd07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Obtain the logistic function mathematically\n",
        "\n",
        "## Step 1. Write out the linear regression equation\n",
        "$\\Huge y=\\beta_0+\\beta_1 x_1+...+\\beta_n x_n$\n",
        "## Step 2. The logistic regression equation is the same as above except output is log odds\n",
        "$\\Huge log(odds)=\\beta_0+\\beta_1 x_1+...+\\beta_n x_n$\n",
        "## Step 3. Exponentiate both sides of the logistic regression equation to get odds\n",
        "$\\Huge odds=e^{\\beta_0+\\beta_1 x_1+...+\\beta_n x_n}$\n",
        "## Step 4. Write out the probability equation\n",
        "$\\Huge p=\\frac{odds}{1+odds}$\n",
        "## Step 5. Plug odds (from step 3) into the probability equation\n",
        "$\\Huge p=\\frac{e^{\\beta_0+\\beta_1 x_1+...+\\beta_n x_n}}{1+e^{\\beta_0+\\beta_1 x_1+...+\\beta_n x_n}}$\n",
        "## Step 6. Divide the numerator and denominator by the odds (from step 3)\n",
        "$\\Huge p=\\frac{1}{1+e^{-(\\beta_0+\\beta_1 x_1+...+\\beta_n x_n)}}$\n"
      ],
      "id": "ab010462"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "cmd = ConfusionMatrixDisplay.from_estimator(gnb, X_test, y_test)\n",
        "plt.show()"
      ],
      "id": "a629ea30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "ct = pd.crosstab(df[\"species\"], df[\"body_mass_g\"] > df[\"body_mass_g\"].mean(), margins=True)"
      ],
      "id": "9def158b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "ct"
      ],
      "id": "4ab3beaa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "likelihood = ct.iloc[0, 0] / ct.iloc[0, 2]\n",
        "likelihood"
      ],
      "id": "4de2314f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "prior = ct.iloc[0, 2] / ct.iloc[3, 2]\n",
        "prior"
      ],
      "id": "c932e785",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "norm =  ct.iloc[3, 0] / ct.iloc[3, 2]\n",
        "norm"
      ],
      "id": "7c4e4e3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "posterior = ct.iloc[0, 0] / ct.iloc[3, 0]\n",
        "posterior"
      ],
      "id": "2d3e3bfa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$\\Huge P(A\\vert B)={\\frac {P(B\\vert A)P(A)}{P(B)}}$\n"
      ],
      "id": "0c79a73a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "result = likelihood * prior / norm"
      ],
      "id": "939c4e3c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "df[\"body_mass_g\"] > df[\"body_mass_g\"].mean()"
      ],
      "id": "761b7ae4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# gnb.fit([df[\"body_mass_g\"] > df[\"body_mass_g\"].mean()], y)"
      ],
      "id": "ce97521f",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/homebrew/Caskroom/miniforge/base/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}